# Unsupervised Learning and Dimensionality Reduction

# Introduction
This report explores two clustering algorithms: k-means and expectation-maximization. It also explores 4 dimensionality reduction algorithms: Principal Component Analysis, Independent Component Analysis, Randomized Projections, and Factor Analysis. Furthermore, the algorithms were applied to a neural network classification problem to draw comparisons on their performance and behaviors.

# Datasets
The code requires the following UCI Machine Learning datasets:
- Abalone Data Set. http://archive.ics.uci.edu/ml/datasets/Abalone
- Letter Recognition Data Set. http://archive.ics.uci.edu/ml/datasets/Letter+Recognition

# Requirements
- Python 2.7.12
- numpy 1.13.3
- pandas 0.18.1
- matplotlib.pyplot 1.5.3
- time
- scikit-learn 0.19.1

# How to Use

--Command Line Instructions--

Run these commands within the code directory.

## Principal-Component Analysis
python pca.py

## Independent Component Analysis
python ica.py

## Randomized Projections
python rp.py

## Factor Analysis
python fa.py

## K-Means
python kmeans.py

## Expectation-Maximization
python em.py